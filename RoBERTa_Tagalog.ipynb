{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d8b9f889db4446f85b8a11945d2b88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11fbf25d3626422a9850707a54ee812f",
              "IPY_MODEL_86fb88413a6c420aa8f1f12d3dc7a93c",
              "IPY_MODEL_12c7881ffcf04c9e8269ea9a249baf16"
            ],
            "layout": "IPY_MODEL_2231636bf88145ae91afcb5e2be5813f"
          }
        },
        "11fbf25d3626422a9850707a54ee812f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f71a06b16c53401f8c6c370656b2d1fa",
            "placeholder": "​",
            "style": "IPY_MODEL_97df750ba7af453b9d89b34c9fde9f20",
            "value": "Map: 100%"
          }
        },
        "86fb88413a6c420aa8f1f12d3dc7a93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bbcfcd54c0140ebaa62906fc3a03455",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d37f0a72df04cd584b3faa55dd1f0d1",
            "value": 40
          }
        },
        "12c7881ffcf04c9e8269ea9a249baf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a962e3d29e9485d83f4c84de08a6104",
            "placeholder": "​",
            "style": "IPY_MODEL_35df88efe0934d21a07c147cc771ef97",
            "value": " 40/40 [00:00&lt;00:00, 786.64 examples/s]"
          }
        },
        "2231636bf88145ae91afcb5e2be5813f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71a06b16c53401f8c6c370656b2d1fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97df750ba7af453b9d89b34c9fde9f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bbcfcd54c0140ebaa62906fc3a03455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d37f0a72df04cd584b3faa55dd1f0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a962e3d29e9485d83f4c84de08a6104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35df88efe0934d21a07c147cc771ef97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ad8c631b20433bbcf83c1e3f421f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1efa01aee2da44f488eae0a67ba48442",
              "IPY_MODEL_a52d2a8b5d1c45978a728611351012ce",
              "IPY_MODEL_321886382e3b4079806a45748ee6dc52"
            ],
            "layout": "IPY_MODEL_f69159159aa44098821fbf42ddcde772"
          }
        },
        "1efa01aee2da44f488eae0a67ba48442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d9ce8f630c4b5dae9881d93039ec84",
            "placeholder": "​",
            "style": "IPY_MODEL_980efd68df914230b61088868a86cb5a",
            "value": "Map: 100%"
          }
        },
        "a52d2a8b5d1c45978a728611351012ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5b1ac9f06d4195ae90f66a6e945dd2",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_665b8880da3e41f1a046528c55dab3b6",
            "value": 10
          }
        },
        "321886382e3b4079806a45748ee6dc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_388a184e461c4e2d95366566965e9a0f",
            "placeholder": "​",
            "style": "IPY_MODEL_7120c5b88f6043df8b40414c9fd99970",
            "value": " 10/10 [00:00&lt;00:00, 203.87 examples/s]"
          }
        },
        "f69159159aa44098821fbf42ddcde772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d9ce8f630c4b5dae9881d93039ec84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980efd68df914230b61088868a86cb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d5b1ac9f06d4195ae90f66a6e945dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665b8880da3e41f1a046528c55dab3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "388a184e461c4e2d95366566965e9a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7120c5b88f6043df8b40414c9fd99970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D58oZ_BtowsG"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/models', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa Tagalog for NSFW word detection"
      ],
      "metadata": {
        "id": "1mBQsUFrpUK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "import tempfile\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "PGFX341Kpgv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBRARIES AND SETUP"
      ],
      "metadata": {
        "id": "xZsl9WUlplot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def install_requirements():\n",
        "    required_packages = [\n",
        "        'transformers[torch]',\n",
        "        'datasets',\n",
        "        'torch',\n",
        "        'pandas',\n",
        "        'scikit-learn',\n",
        "        'onnx',\n",
        "        'onnxruntime',\n",
        "        'optimum[onnxruntime]',  # This enables ORTModelForSequenceClassification\n",
        "        'tensorflow',\n",
        "    ]\n",
        "\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package.split('[')[0])\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
      ],
      "metadata": {
        "id": "tviqawhep6F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking and installing dependencies...\")\n",
        "install_requirements()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx9ZsfNGp-Bv",
        "outputId": "5da9e16d-d3fd-449f-c449-baf665cb666a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking and installing dependencies...\n",
            "Installing scikit-learn...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from optimum.onnxruntime import ORTModelForSequenceClassification\n",
        "    from optimum.onnxruntime.configuration import OptimizationConfig\n",
        "    ONNX_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Optimum ONNX Runtime not available, ONNX export will be limited\")\n",
        "    ONNX_AVAILABLE = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw8--Ez1p_ry",
        "outputId": "a3ac6dcf-53a3-4998-ae86-79ffe126889e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimum ONNX Runtime not available, ONNX export will be limited\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All dependencies loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0F9J6LPqJwJ",
        "outputId": "ad8b4687-5591-4b63-d660-1b7d06ce454b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD AND PREPARE DATASET"
      ],
      "metadata": {
        "id": "uBSpKsUEqL50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(csv_path='dataset.csv'):\n",
        "    print(f\"Loading dataset from {csv_path}...\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['text', 'label']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Clean and validate data\n",
        "        df = df.dropna(subset=['text', 'label'])\n",
        "        df['text'] = df['text'].astype(str)\n",
        "        df['label'] = df['label'].astype(int)\n",
        "\n",
        "        # Validate labels are binary (0, 1) for NSFW detection\n",
        "        unique_labels = df['label'].unique()\n",
        "        if not all(label in [0, 1] for label in unique_labels):\n",
        "            raise ValueError(\"Labels must be 0 (safe) or 1 (nsfw)\")\n",
        "\n",
        "        print(f\"Dataset validation complete. Clean shape: {df.shape}\")\n",
        "        print(f\"Label distribution:\\n{df['label'].value_counts()}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file '{csv_path}' not found!\")\n",
        "        print(\"Creating a sample dataset for demonstration...\")\n",
        "        return create_sample_dataset()"
      ],
      "metadata": {
        "id": "-DhJB9IdqQdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_dataset():\n",
        "    sample_data = {\n",
        "        'text': [\n",
        "            # Safe content (Tagalog examples) - 30 examples\n",
        "            'Magandang umaga sa lahat', 'Kumusta kayo ngayong araw', 'Salamat sa inyong tulong',\n",
        "            'Masayang pagdating ng bagong taon', 'Ang ganda ng bulaklak sa hardin',\n",
        "            'Nag-aaral ako ng Filipino', 'Masarap ang pagkain sa kusina', 'Magandang morning',\n",
        "            'Magandang panahon ngayon', 'Nagbabasa ako ng libro', 'Maligayang kaarawan',\n",
        "            'Ang sarap ng mangga', 'Nood tayo ng pelikula', 'Magandang gabi sa inyo',\n",
        "            'Ang galing ng mga estudyante', 'Masaya sa probinsya', 'Maayos na klase ngayon',\n",
        "            'Magandang simula ng linggo', 'Ang husay ng mga guro', 'Masayang samahan',\n",
        "            'Good morning everyone', 'How are you today', 'Thank you for your help',\n",
        "            'Beautiful flowers in the garden', 'I am studying', 'Nice weather today',\n",
        "            'Reading a good book', 'Happy birthday', 'Delicious mango', 'Watching movies',\n",
        "            # NSFW content (placeholder examples) - 20 examples\n",
        "            'inappropriate tagalog content 1', 'inappropriate content 2', 'bad words example 3',\n",
        "            'inappropriate tagalog 4', 'nsfw content 5', 'inappropriate 6',\n",
        "            'bad content 7', 'inappropriate tagalog 8', 'nsfw example 9',\n",
        "            'inappropriate content 10', 'bad words 11', 'inappropriate 12',\n",
        "            'nsfw tagalog 13', 'inappropriate content 14', 'bad example 15',\n",
        "            'inappropriate 16', 'nsfw content 17', 'bad words tagalog 18',\n",
        "            'inappropriate content 19', 'nsfw example 20'\n",
        "        ],\n",
        "        'label': [0] * 30 + [1] * 20  # 30 safe, 20 nsfw\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    df.to_csv('dataset.csv', index=False)\n",
        "    print(\"Sample dataset created and saved as 'dataset.csv'\")\n",
        "    print(\"Note: Replace placeholder NSFW examples with actual data for real training\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "UNOLvdfdqXVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(df, test_size=0.2, random_state=42):\n",
        "    print(f\"Splitting dataset: {test_size*100}% for validation...\")\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        df['text'].tolist(),\n",
        "        df['label'].tolist(),\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=df['label']\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Validation set: {len(X_val)} samples\")\n",
        "\n",
        "    return X_train, X_val, y_train, y_val"
      ],
      "metadata": {
        "id": "kaaqSKPKqZmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZATION AND PREPROCESSING"
      ],
      "metadata": {
        "id": "YeELj604qbhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokenized_datasets(X_train, X_val, y_train, y_val, model_name):\n",
        "    \"\"\"Tokenize the datasets using the RoBERTa Tagalog tokenizer\"\"\"\n",
        "    print(\"Loading RoBERTa Tagalog tokenizer and creating tokenized datasets...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Check if tokenizer has pad_token, add if missing\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = Dataset.from_dict({\n",
        "        'text': X_train,\n",
        "        'labels': y_train\n",
        "    })\n",
        "\n",
        "    val_dataset = Dataset.from_dict({\n",
        "        'text': X_val,\n",
        "        'labels': y_val\n",
        "    })\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            truncation=True,\n",
        "            padding=False,  # Will be handled by data collator\n",
        "            max_length=256  # Increased for better Tagalog sentence handling\n",
        "        )\n",
        "\n",
        "    # Tokenize datasets\n",
        "    train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
        "    val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    print(\"Tokenization complete!\")\n",
        "    return train_tokenized, val_tokenized, tokenizer"
      ],
      "metadata": {
        "id": "hXIT2KpuqkKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING\n",
        "\n"
      ],
      "metadata": {
        "id": "tTmdDUvyqm08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataset, val_dataset, tokenizer, model_name, output_dir):\n",
        "    \"\"\"Train the RoBERTa Tagalog model for NSFW detection\"\"\"\n",
        "    print(\"Initializing RoBERTa Tagalog model for NSFW detection training...\")\n",
        "\n",
        "    # Load model with binary classification (NSFW vs Safe)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2,\n",
        "        id2label={0: \"Safe\", 1: \"NSFW\"},\n",
        "        label2id={\"Safe\": 0, \"NSFW\": 1}\n",
        "    )\n",
        "\n",
        "    # Ensure model uses the correct pad_token_id\n",
        "    if tokenizer.pad_token_id is not None:\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    # Training arguments optimized for RoBERTa Tagalog\n",
        "    training_args_dict = {\n",
        "        'output_dir': output_dir,\n",
        "        'num_train_epochs': 3,  # Reduced epochs for fine-tuning\n",
        "        'per_device_train_batch_size': 8,  # Smaller batch size for stability\n",
        "        'per_device_eval_batch_size': 8,\n",
        "        'learning_rate': 3e-5,  # Slightly higher learning rate for RoBERTa\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_steps': 100,  # Warmup for better training stability\n",
        "        'logging_dir': f'{output_dir}/logs',\n",
        "        'logging_steps': 10,\n",
        "        'save_total_limit': 2,\n",
        "        'load_best_model_at_end': True,\n",
        "        'metric_for_best_model': \"eval_loss\",\n",
        "        'greater_is_better': False,\n",
        "        'report_to': [],\n",
        "        'seed': 42,\n",
        "        'dataloader_num_workers': 0,\n",
        "        'remove_unused_columns': True,\n",
        "        'fp16': True,  # Enable mixed precision for efficiency\n",
        "    }\n",
        "\n",
        "    # Add version-specific parameters\n",
        "    if hasattr(TrainingArguments, 'eval_strategy'):\n",
        "        # New version\n",
        "        training_args_dict['eval_strategy'] = \"epoch\"\n",
        "        training_args_dict['save_strategy'] = \"epoch\"\n",
        "    else:\n",
        "        # Old version\n",
        "        training_args_dict['evaluation_strategy'] = \"epoch\"\n",
        "        training_args_dict['save_strategy'] = \"epoch\"\n",
        "\n",
        "    training_args = TrainingArguments(**training_args_dict)\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "\n",
        "        # Handle different prediction formats\n",
        "        if isinstance(predictions, tuple):\n",
        "            # If predictions is a tuple, take the first element (logits)\n",
        "            predictions = predictions[0]\n",
        "\n",
        "        # Convert to numpy array if it's a tensor\n",
        "        if hasattr(predictions, 'numpy'):\n",
        "            predictions = predictions.numpy()\n",
        "\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy_score(labels, predictions),\n",
        "        }\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the best model\n",
        "    print(f\"Saving model to {output_dir}...\")\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    return trainer, model"
      ],
      "metadata": {
        "id": "6GN3zJdYqoXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL EVALUATION"
      ],
      "metadata": {
        "id": "KRH5QEoUqvzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(trainer, X_val, y_val, output_dir):\n",
        "    print(\"Evaluating model performance...\")\n",
        "\n",
        "    try:\n",
        "        # Get predictions using trainer.predict\n",
        "        predictions_output = trainer.predict(trainer.eval_dataset)\n",
        "\n",
        "        # Debug: Print the structure of predictions\n",
        "        print(f\"Debug: Predictions structure type: {type(predictions_output)}\")\n",
        "\n",
        "        # Handle different prediction formats\n",
        "        if hasattr(predictions_output, 'predictions'):\n",
        "            preds = predictions_output.predictions\n",
        "            print(f\"Debug: predictions shape: {np.array(preds).shape if isinstance(preds, np.ndarray) else 'not array'}\")\n",
        "        else:\n",
        "            # Handle tuple format\n",
        "            preds = predictions_output[0] if isinstance(predictions_output, tuple) else predictions_output\n",
        "            print(f\"Debug: extracted predictions shape: {np.array(preds).shape if isinstance(preds, np.ndarray) else 'not array'}\")\n",
        "\n",
        "        # Convert to numpy array properly\n",
        "        if hasattr(preds, 'numpy'):\n",
        "            preds = preds.numpy()\n",
        "        elif not isinstance(preds, np.ndarray):\n",
        "            preds = np.array(preds)\n",
        "\n",
        "        print(f\"Debug: Final preds shape: {preds.shape}\")\n",
        "        print(f\"Debug: First few predictions: {preds[:2] if len(preds) > 0 else 'empty'}\")\n",
        "\n",
        "        # Ensure preds is 2D for argmax\n",
        "        if preds.ndim == 1:\n",
        "            print(\"Warning: Predictions are 1D, assuming binary classification with single logits\")\n",
        "            # For binary classification, if we have single values, convert to probabilities\n",
        "            y_pred = (preds > 0).astype(int)\n",
        "        else:\n",
        "            # Normal case: 2D array with logits/probabilities for each class\n",
        "            y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "        print(f\"Debug: y_pred shape: {y_pred.shape}\")\n",
        "        print(f\"Debug: y_val length: {len(y_val)}\")\n",
        "\n",
        "        # Get evaluation results from trainer\n",
        "        eval_results = trainer.evaluate()\n",
        "\n",
        "        # Generate classification report\n",
        "        report = classification_report(\n",
        "            y_val,\n",
        "            y_pred,\n",
        "            target_names=['Safe', 'NSFW'],\n",
        "            digits=4\n",
        "        )\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "        # Prepare metrics text\n",
        "        metrics_text = f\"\"\"RoBERTa Tagalog NSFW Detection Model Evaluation Results\n",
        "{'='*60}\n",
        "\n",
        "Model: danjohnvelasco/roberta-tagalog-base-cohfie-v1\n",
        "Task: Binary Classification (Safe vs NSFW)\n",
        "\n",
        "Accuracy: {accuracy:.4f}\n",
        "\n",
        "Classification Report:\n",
        "{report}\n",
        "\n",
        "Training Results:\n",
        "{'-'*30}\n",
        "\"\"\"\n",
        "\n",
        "        for key, value in eval_results.items():\n",
        "            metrics_text += f\"{key}: {value:.4f}\\n\"\n",
        "\n",
        "        # Save metrics\n",
        "        os.makedirs('metrics', exist_ok=True)\n",
        "        metrics_path = 'metrics/metrics.txt'\n",
        "\n",
        "        with open(metrics_path, 'w') as f:\n",
        "            f.write(metrics_text)\n",
        "\n",
        "        print(f\"Metrics saved to {metrics_path}\")\n",
        "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return accuracy, report\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in evaluation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Fallback evaluation using manual prediction\n",
        "        print(\"Attempting fallback evaluation...\")\n",
        "        return evaluate_model_fallback(trainer, X_val, y_val, output_dir)"
      ],
      "metadata": {
        "id": "hRUvaLcvq0XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_fallback(trainer, X_val, y_val, output_dir):\n",
        "    \"\"\"Fallback evaluation method using manual prediction\"\"\"\n",
        "    print(\"Using fallback evaluation method...\")\n",
        "\n",
        "    try:\n",
        "        model = trainer.model\n",
        "        tokenizer = trainer.tokenizer\n",
        "        model.eval()\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for text in X_val:\n",
        "            # Tokenize each text individually\n",
        "            inputs = tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=256,\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "            # Move to same device as model\n",
        "            inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "                pred = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n",
        "                predictions.append(pred)\n",
        "\n",
        "        y_pred = np.array(predictions)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "        # Generate classification report\n",
        "        report = classification_report(\n",
        "            y_val,\n",
        "            y_pred,\n",
        "            target_names=['Safe', 'NSFW'],\n",
        "            digits=4\n",
        "        )\n",
        "\n",
        "        # Prepare metrics text\n",
        "        metrics_text = f\"\"\"RoBERTa Tagalog NSFW Detection Model Evaluation Results (Fallback)\n",
        "{'='*60}\n",
        "\n",
        "Model: danjohnvelasco/roberta-tagalog-base-cohfie-v1\n",
        "Task: Binary Classification (Safe vs NSFW)\n",
        "\n",
        "Accuracy: {accuracy:.4f}\n",
        "\n",
        "Classification Report:\n",
        "{report}\n",
        "\"\"\"\n",
        "\n",
        "        # Save metrics\n",
        "        os.makedirs('metrics', exist_ok=True)\n",
        "        metrics_path = 'metrics/metrics.txt'\n",
        "\n",
        "        with open(metrics_path, 'w') as f:\n",
        "            f.write(metrics_text)\n",
        "\n",
        "        print(f\"Metrics saved to {metrics_path}\")\n",
        "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return accuracy, report\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Fallback evaluation also failed: {e}\")\n",
        "        return 0.0, \"Evaluation failed\"\n"
      ],
      "metadata": {
        "id": "WjeK5_KGwFMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX EXPORT"
      ],
      "metadata": {
        "id": "xJU6E6sEq3Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_onnx(model_dir, onnx_path):\n",
        "    print(\"Exporting RoBERTa Tagalog model to ONNX format...\")\n",
        "\n",
        "    try:\n",
        "        # Load the trained model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "        # Create dummy input with sample Tagalog text\n",
        "        dummy_input = tokenizer(\n",
        "            \"Magandang umaga sa lahat\",\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=256,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        # Export to ONNX with optimization for RoBERTa\n",
        "        os.makedirs(os.path.dirname(onnx_path), exist_ok=True)\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            tuple(dummy_input.values()),\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=14,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input_ids', 'attention_mask'],\n",
        "            output_names=['logits'],\n",
        "            dynamic_axes={\n",
        "                'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
        "                'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
        "                'logits': {0: 'batch_size'}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "        print(f\"ONNX model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ONNX export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "UX8Lhz9Fq526"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSORFLOW LITE EXPORT"
      ],
      "metadata": {
        "id": "TzS7qpVnq8PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_tflite_from_pt(model_dir, tflite_path):\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
        "        import os\n",
        "\n",
        "        print(\"Converting RoBERTa Tagalog PyTorch model to TensorFlow...\")\n",
        "\n",
        "        # Load and convert to TensorFlow\n",
        "        tf_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "            model_dir,\n",
        "            from_pt=True  # convert from PyTorch\n",
        "        )\n",
        "\n",
        "        # Save as TensorFlow SavedModel\n",
        "        tf_saved_model_dir = os.path.join(model_dir, \"tf_saved_model\")\n",
        "        tf.saved_model.save(tf_model, tf_saved_model_dir)\n",
        "        print(f\"Saved intermediate TensorFlow model to {tf_saved_model_dir}\")\n",
        "\n",
        "        # Convert to TFLite with optimizations\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_saved_model_dir)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "        # Additional optimizations for mobile deployment\n",
        "        converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save TFLite model\n",
        "        os.makedirs(os.path.dirname(tflite_path), exist_ok=True)\n",
        "        with open(tflite_path, \"wb\") as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"TFLite model successfully exported to: {tflite_path}\")\n",
        "        print(f\"TFLite model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow Lite export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "-OSXKUOFrBpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "Ih2JQH8rrEQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Starting RoBERTa Tagalog NSFW Detection Model Training Pipeline\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Configuration - Updated to use RoBERTa Tagalog model\n",
        "    MODEL_NAME = \"danjohnvelasco/roberta-tagalog-base-cohfie-v1\"\n",
        "    OUTPUT_DIR = \"models/roberta_tagalog_nsfw\"\n",
        "    ONNX_PATH = \"models/roberta_tagalog_nsfw_model.onnx\"\n",
        "    TFLITE_PATH = \"models/roberta_tagalog_nsfw_model.tflite\"\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    os.makedirs(\"metrics\", exist_ok=True)\n",
        "\n",
        "    print(f\"Using model: {MODEL_NAME}\")\n",
        "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "    # Step 1: Load dataset\n",
        "    df = load_dataset()\n",
        "\n",
        "    # Step 2: Split dataset\n",
        "    X_train, X_val, y_train, y_val = split_dataset(df)\n",
        "\n",
        "    # Step 3: Create tokenized datasets\n",
        "    train_dataset, val_dataset, tokenizer = create_tokenized_datasets(\n",
        "        X_train, X_val, y_train, y_val, MODEL_NAME\n",
        "    )\n",
        "\n",
        "    # Step 4: Train model\n",
        "    trainer, model = train_model(\n",
        "        train_dataset, val_dataset, tokenizer, MODEL_NAME, OUTPUT_DIR\n",
        "    )\n",
        "\n",
        "    # Step 5: Evaluate model\n",
        "    accuracy, report = evaluate_model(trainer, X_val, y_val, OUTPUT_DIR)\n",
        "\n",
        "    # Step 6: Export to ONNX\n",
        "    onnx_success = export_to_onnx(OUTPUT_DIR, ONNX_PATH)\n",
        "\n",
        "    # Step 7: Export to TFLite\n",
        "    tflite_success = export_to_tflite_from_pt(OUTPUT_DIR, TFLITE_PATH)\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RoBERTa Tagalog NSFW Detection Training Complete!\")\n",
        "\n",
        "    if onnx_success:\n",
        "        print(f\"✅ ONNX model: {ONNX_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ ONNX export: FAILED\")\n",
        "\n",
        "    if tflite_success:\n",
        "        print(f\"✅ TFLite model: {TFLITE_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ TFLite export: FAILED\")\n",
        "\n",
        "    print(f\"\\nModel checkpoints: {OUTPUT_DIR}\")\n",
        "    print(f\"Metrics: metrics/metrics.txt\")\n",
        "    print(f\"Final validation accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "dvVomQfJrH5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INFERENCE"
      ],
      "metadata": {
        "id": "Qp815I9DrLBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference(model_dir, test_texts=None):\n",
        "    if test_texts is None:\n",
        "        test_texts = [\n",
        "            \"Magandang umaga sa lahat\",  # Safe Tagalog\n",
        "            \"Good morning everyone\",     # Safe English\n",
        "            \"inappropriate example\"      # NSFW placeholder\n",
        "        ]\n",
        "\n",
        "    print(\"\\nTesting trained RoBERTa Tagalog model...\")\n",
        "\n",
        "    try:\n",
        "        # Load model and tokenizer\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        for text in test_texts:\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=256,\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "            # Predict\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "                predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "                confidence = predictions[0][predicted_class].item()\n",
        "\n",
        "            # Map predictions to labels\n",
        "            label = \"Safe\" if predicted_class == 0 else \"NSFW\"\n",
        "            safe_prob = predictions[0][0].item()\n",
        "            nsfw_prob = predictions[0][1].item()\n",
        "\n",
        "            print(f\"Text: '{text}' -> {label} (confidence: {confidence:.4f})\")\n",
        "            print(f\"  Probabilities: Safe={safe_prob:.4f}, NSFW={nsfw_prob:.4f}\")\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Inference test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "_y4noVMnrOrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROGRAM EXECUTION"
      ],
      "metadata": {
        "id": "i8l7KptyrQfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run the main pipeline\n",
        "        main()\n",
        "\n",
        "        # Optional: Test inference\n",
        "        test_inference(\"models/roberta_tagalog_nsfw\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nTraining interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\nProgram execution completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4d8b9f889db4446f85b8a11945d2b88d",
            "11fbf25d3626422a9850707a54ee812f",
            "86fb88413a6c420aa8f1f12d3dc7a93c",
            "12c7881ffcf04c9e8269ea9a249baf16",
            "2231636bf88145ae91afcb5e2be5813f",
            "f71a06b16c53401f8c6c370656b2d1fa",
            "97df750ba7af453b9d89b34c9fde9f20",
            "5bbcfcd54c0140ebaa62906fc3a03455",
            "7d37f0a72df04cd584b3faa55dd1f0d1",
            "7a962e3d29e9485d83f4c84de08a6104",
            "35df88efe0934d21a07c147cc771ef97",
            "f1ad8c631b20433bbcf83c1e3f421f2e",
            "1efa01aee2da44f488eae0a67ba48442",
            "a52d2a8b5d1c45978a728611351012ce",
            "321886382e3b4079806a45748ee6dc52",
            "f69159159aa44098821fbf42ddcde772",
            "23d9ce8f630c4b5dae9881d93039ec84",
            "980efd68df914230b61088868a86cb5a",
            "4d5b1ac9f06d4195ae90f66a6e945dd2",
            "665b8880da3e41f1a046528c55dab3b6",
            "388a184e461c4e2d95366566965e9a0f",
            "7120c5b88f6043df8b40414c9fd99970"
          ]
        },
        "id": "n7INgz4arTm3",
        "outputId": "f1b8c4d5-f788-400a-ef51-adc0a94f0cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting RoBERTa Tagalog NSFW Detection Model Training Pipeline\n",
            "======================================================================\n",
            "Using model: danjohnvelasco/roberta-tagalog-base-cohfie-v1\n",
            "Output directory: models/roberta_tagalog_nsfw\n",
            "Loading dataset from dataset.csv...\n",
            "Dataset loaded successfully. Shape: (50, 2)\n",
            "Dataset validation complete. Clean shape: (50, 2)\n",
            "Label distribution:\n",
            "label\n",
            "0    30\n",
            "1    20\n",
            "Name: count, dtype: int64\n",
            "Splitting dataset: 20.0% for validation...\n",
            "Training set: 40 samples\n",
            "Validation set: 10 samples\n",
            "Loading RoBERTa Tagalog tokenizer and creating tokenized datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d8b9f889db4446f85b8a11945d2b88d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1ad8c631b20433bbcf83c1e3f421f2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete!\n",
            "Initializing RoBERTa Tagalog model for NSFW detection training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at danjohnvelasco/roberta-tagalog-base-cohfie-v1 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1417487496.py:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:40, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.698926</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.682600</td>\n",
              "      <td>0.654199</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.682600</td>\n",
              "      <td>0.586841</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to models/roberta_tagalog_nsfw...\n",
            "Evaluating model performance...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2995707972.py\", line 24, in evaluate_model\n",
            "    preds = np.array(preds)\n",
            "            ^^^^^^^^^^^^^^^\n",
            "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug: Predictions structure type: <class 'transformers.trainer_utils.PredictionOutput'>\n",
            "Debug: predictions shape: not array\n",
            "Error in evaluation: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
            "Attempting fallback evaluation...\n",
            "Using fallback evaluation method...\n",
            "Metrics saved to metrics/metrics.txt\n",
            "Validation Accuracy: 0.8000\n",
            "Exporting RoBERTa Tagalog model to ONNX format...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1325384116.py:20: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model exported to: models/roberta_tagalog_nsfw_model.onnx\n",
            "ONNX model size: 416.44 MB\n",
            "Converting RoBERTa Tagalog PyTorch model to TensorFlow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved intermediate TensorFlow model to models/roberta_tagalog_nsfw/tf_saved_model\n",
            "TFLite model successfully exported to: models/roberta_tagalog_nsfw_model.tflite\n",
            "TFLite model size: 208.35 MB\n",
            "\n",
            "======================================================================\n",
            "RoBERTa Tagalog NSFW Detection Training Complete!\n",
            "✅ ONNX model: models/roberta_tagalog_nsfw_model.onnx\n",
            "✅ TFLite model: models/roberta_tagalog_nsfw_model.tflite\n",
            "\n",
            "Model checkpoints: models/roberta_tagalog_nsfw\n",
            "Metrics: metrics/metrics.txt\n",
            "Final validation accuracy: 0.8000\n",
            "\n",
            "Testing trained RoBERTa Tagalog model...\n",
            "Text: 'Magandang umaga sa lahat' -> NSFW (confidence: 0.5137)\n",
            "  Probabilities: Safe=0.4863, NSFW=0.5137\n",
            "\n",
            "Text: 'Good morning everyone' -> NSFW (confidence: 0.5226)\n",
            "  Probabilities: Safe=0.4774, NSFW=0.5226\n",
            "\n",
            "Text: 'inappropriate example' -> NSFW (confidence: 0.6637)\n",
            "  Probabilities: Safe=0.3363, NSFW=0.6637\n",
            "\n",
            "\n",
            "Program execution completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create zip of entire content folder\n",
        "!zip -r /content/colab_content.zip /content/\n",
        "\n",
        "# Download the zip\n",
        "from google.colab import files\n",
        "files.download('/content/colab_content.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NUm2SxKexDef",
        "outputId": "32df3ac9-f356-4fc4-ac57-beb845d15419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/default_configs.db (deflated 98%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.09.16/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.09.16/13.39.51.530260.log (deflated 92%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.25.424362.log (deflated 86%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.37.615954.log (deflated 57%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.15.959626.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.38.414999.log (deflated 56%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.27.693438.log (deflated 58%)\n",
            "  adding: content/metrics/ (stored 0%)\n",
            "  adding: content/metrics/metrics.txt (deflated 55%)\n",
            "  adding: content/models/ (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw_model.tflite (deflated 8%)\n",
            "  adding: content/models/roberta_tagalog_nsfw_model.onnx (deflated 7%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/ (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/model.safetensors (deflated 7%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/ (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/model.safetensors (deflated 7%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/scheduler.pt (deflated 61%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/added_tokens.json (deflated 48%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/training_args.bin (deflated 54%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/scaler.pt (deflated 64%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/optimizer.pt (deflated 27%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/config.json (deflated 51%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/rng_state.pth (deflated 26%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/merges.txt (deflated 55%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/vocab.json (deflated 59%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/tokenizer_config.json (deflated 82%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/tokenizer.json (deflated 82%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/trainer_state.json (deflated 61%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-10/special_tokens_map.json (deflated 79%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/added_tokens.json (deflated 48%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/ (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/model.safetensors (deflated 7%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/scheduler.pt (deflated 61%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/added_tokens.json (deflated 48%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/training_args.bin (deflated 54%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/scaler.pt (deflated 64%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/optimizer.pt (deflated 28%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/config.json (deflated 51%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/rng_state.pth (deflated 26%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/merges.txt (deflated 55%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/vocab.json (deflated 59%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/tokenizer_config.json (deflated 82%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/tokenizer.json (deflated 82%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/trainer_state.json (deflated 64%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/checkpoint-15/special_tokens_map.json (deflated 79%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/training_args.bin (deflated 54%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/config.json (deflated 51%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/merges.txt (deflated 55%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/vocab.json (deflated 59%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tokenizer_config.json (deflated 82%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tokenizer.json (deflated 82%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tf_saved_model/ (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tf_saved_model/saved_model.pb (deflated 92%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tf_saved_model/assets/ (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tf_saved_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tf_saved_model/variables/ (stored 0%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tf_saved_model/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/tf_saved_model/variables/variables.index (deflated 77%)\n",
            "  adding: content/models/roberta_tagalog_nsfw/special_tokens_map.json (deflated 79%)\n",
            "  adding: content/dataset.csv (deflated 57%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f9c9f661-c8b4-4f3b-8576-cba47fdbb2ff\", \"colab_content.zip\", 3492576042)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}